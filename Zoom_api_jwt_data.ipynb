{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab4b9c1-509d-44e9-975a-f3681a27868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import time\n",
    "from espressomaker import Espresso\n",
    "from zoomus import ZoomClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e3763c-236f-4618-84e5-cc35f26fde00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key and secret necessary for API access - omitted from git push\n",
    "key = ''\n",
    "secret = ''\n",
    "\n",
    "#Zoomus creates a client for API requests, and can call requests as python methods on the client object\n",
    "client = ZoomClient(key, secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2446dacb-d69e-4e5b-8dea-c8fb819bcdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_list(make_df = True, key = key, secret = secret):\n",
    "    user_data = json.loads(client.user.list().content)\n",
    "    users = user_data['users']\n",
    "    pages = user_data['page_count']\n",
    "    \n",
    "    for page in range(2, pages + 1):\n",
    "        next_page = json.loads(client.user.list(page_number = page).content)\n",
    "        users.extend(next_page['users'])\n",
    "#     if 'next_page_token' in user_data.keys():\n",
    "#         page_turn = json.loads(client.user.list(next_page_token = user_data['next_page_token']).content)\n",
    "#         users.extend(page_turn['users'])\n",
    "#         while True:\n",
    "#             #This should redefine page_turn as the following page repeatedly, then add to users,\n",
    "#             #until the final page is reached, which, and in the following iteration it will break\n",
    "#             if 'next_page_token' in page_turn.keys():\n",
    "#                 key = page_turn['next_page_token']\n",
    "#                 page_turn = json.loads(client.user.list(next_page_token = key).content)\n",
    "#                 users.extend(page_turn['users'])\n",
    "\n",
    "#             if 'next_page_token' not in page_turn.keys():\n",
    "#                 break\n",
    "    \n",
    "    if make_df == False:\n",
    "        return users\n",
    "    else:\n",
    "        return pd.DataFrame(users)\n",
    "    \n",
    "def user_list():\n",
    "    user_df = generate_user_list()\n",
    "    user_list = user_df.id.unique().tolist()\n",
    "    \n",
    "    return user_list\n",
    "\n",
    "def get_meetings(end_date = datetime.date.today(), num_months = 5, just_today = False, return_json = False,\n",
    "                key = key, secret = secret):\n",
    "    #Note: cannot search more than 30 days at a time - choose num_months and days = 30 instead. Also, cannot search\n",
    "    #more than 6 months into the past\n",
    "\n",
    "\n",
    "    client = ZoomClient(key, secret)\n",
    "    count = 0\n",
    "    fails = []\n",
    "    \n",
    "    all_user_ids = user_list()\n",
    "    if just_today == False:\n",
    "        delta = datetime.timedelta(days = 30)\n",
    "        start = end_date - delta\n",
    "    \n",
    "    if just_today == True:\n",
    "        delta = datetime.timedelta(days = 1)\n",
    "        start = end_date - delta\n",
    "    #This will house all users' meeting lists as dictionary objects\n",
    "    meeting_list = []\n",
    "    \n",
    "#     temp = json.loads(client.report.get_user_report(\n",
    "#             user_id = user, start_time = start , end_time = end_date - num * delta).content)['meetings']\n",
    "    \n",
    "    \n",
    "    if just_today == False:\n",
    "        for user in all_user_ids:\n",
    "            for num in range(num_months + 1):\n",
    "                try:\n",
    "                    data = json.loads(client.report.get_user_report(\n",
    "                        user_id = user, start_time = start - num * delta, \n",
    "                        end_time = end_date - num * delta).content)\n",
    "                    \n",
    "                    temp = data['meetings']\n",
    "                    while True:\n",
    "                        if 'next_page_token' not in data.keys():\n",
    "                            break\n",
    "                        if data['next_page_token'] == '':\n",
    "                            break\n",
    "                        try:\n",
    "                            next_page = data['next_page_token']\n",
    "                            data = json.loads(client.report.get_user_report(\n",
    "                                user_id = user, start_time = start - num * delta, \n",
    "                                end_time = end_date - num * delta, next_page_token = next_page).content)\n",
    "                            temp.extend(data['meetings'])\n",
    "                            time.sleep(0.3)\n",
    "                        except KeyError:\n",
    "                    #This most likely means that the client access expired and needs to be refreshed\n",
    "\n",
    "                            client = ZoomClient(key, secret)\n",
    "                    \n",
    "                    meeting_list.append(temp)\n",
    "                    time.sleep(0.3)\n",
    "                except KeyError:\n",
    "                    #This most likely means that the client access expired and needs to be refreshed\n",
    "\n",
    "                    client = ZoomClient(key, secret)\n",
    "                    \n",
    "                    try:\n",
    "                        data = json.loads(client.report.get_user_report(\n",
    "                            user_id = user, start_time = start - num * delta, \n",
    "                            end_time = end_date - num * delta).content)\n",
    "                        temp = data['meetings']\n",
    "                        while True:\n",
    "                            if 'next_page_token' not in data.keys():\n",
    "                                break\n",
    "                            if data['next_page_token'] == '':\n",
    "                                break\n",
    "                            try:\n",
    "                                next_page = data['next_page_token']\n",
    "                                data = json.loads(client.report.get_user_report(\n",
    "                                    user_id = user, start_time = start - num * delta, \n",
    "                                    end_time = end_date - num * delta, next_page_token = next_page).content)\n",
    "                                temp.extend(data['meetings'])\n",
    "                                time.sleep(0.3)\n",
    "                            except KeyError:\n",
    "                                break\n",
    "\n",
    "                        meeting_list.append(temp)\n",
    "                        time.sleep(0.3)\n",
    "                    except KeyError:\n",
    "                        #A keyerror means that the given user has no meetings available in their data for some reason\n",
    "                        count += 1\n",
    "                        fails.append(user)\n",
    "                        #I want to know how many fails occurred \n",
    "                        continue\n",
    "                \n",
    "    if just_today == True:\n",
    "        for user in all_user_ids:\n",
    "            try:\n",
    "                data = json.loads(client.report.get_user_report(\n",
    "                    user_id = user, start_time = start, \n",
    "                    end_time = end_date).content)\n",
    "\n",
    "                temp = data['meetings']\n",
    "                while True:\n",
    "                    if 'next_page_token' not in data.keys():\n",
    "                        break\n",
    "                    if data['next_page_token'] == '':\n",
    "                        break\n",
    "                    try:\n",
    "                        next_page = data['next_page_token']\n",
    "                        data = json.loads(client.report.get_user_report(\n",
    "                            user_id = user, start_time = start, \n",
    "                            end_time = end_date, next_page_token = next_page).content)\n",
    "                        temp.extend(data['meetings'])\n",
    "                        time.sleep(0.3)\n",
    "                    except KeyError:\n",
    "                #This most likely means that the client access expired and needs to be refreshed\n",
    "\n",
    "                        client = ZoomClient(key, secret)\n",
    "\n",
    "                meeting_list.append(temp)\n",
    "                time.sleep(0.3)\n",
    "            except KeyError:\n",
    "                #This most likely means that the client access expired and needs to be refreshed\n",
    "\n",
    "                client = ZoomClient(key, secret)\n",
    "\n",
    "                try:\n",
    "                    data = json.loads(client.report.get_user_report(\n",
    "                        user_id = user, start_time = start, \n",
    "                        end_time = end_date).content)\n",
    "                    temp = data['meetings']\n",
    "                    while True:\n",
    "                        if 'next_page_token' not in data.keys():\n",
    "                            break\n",
    "                        if data['next_page_token'] == '':\n",
    "                            break\n",
    "                        try:\n",
    "                            next_page = data['next_page_token']\n",
    "                            data = json.loads(client.report.get_user_report(\n",
    "                                user_id = user, start_time = start, \n",
    "                                end_time = end_date, next_page_token = next_page).content)\n",
    "                            temp.extend(data['meetings'])\n",
    "                            time.sleep(0.3)\n",
    "                        except KeyError:\n",
    "                            break\n",
    "\n",
    "                    meeting_list.append(temp)\n",
    "                    time.sleep(0.3)\n",
    "                except KeyError:\n",
    "                    #A keyerror means that the given user has no meetings available in their data for some reason\n",
    "                    count += 1\n",
    "                    fails.append(user)\n",
    "                    #I want to know how many fails occurred \n",
    "                    continue\n",
    "\n",
    "    ret_list = []\n",
    "    for i in meeting_list:\n",
    "        if len(i) > 0:\n",
    "            for meeting in i:\n",
    "                ret_list.append(meeting)\n",
    "    \n",
    "    if return_json == True:\n",
    "        ret_dict = {}\n",
    "        for record in range(len(ret_list)):\n",
    "            ret_list[record]['meeting_id'] = ret_list[record].pop('id')\n",
    "            try:\n",
    "                ret_list[record]['Epic CSN'] = ret_list[record]['custom_keys'][0]['value']\n",
    "            except KeyError:\n",
    "                #This indicates a null value\n",
    "                ret_list[record]['Epic CSN'] = np.NaN\n",
    "            ret_dict[record] = ret_list[record]\n",
    "        return ret_dict\n",
    "                \n",
    "    ret_df = pd.DataFrame(ret_list)\n",
    "    ret_df.rename(columns = {'id':'meeting_id'}, inplace = True)\n",
    "    ret_df['epic_csn'] = ret_df.custom_keys.apply(lambda x: int(x[0]['value']) if not pd.isnull(x) else x)\n",
    "    ret_df.drop(columns = ['uuid','topic', \n",
    "                          'type','source', 'custom_keys'], inplace = True)\n",
    "            \n",
    "    print(count)\n",
    "    print(fails)\n",
    "    return ret_df\n",
    "\n",
    "def get_participants(meeting_df, return_json = False, key = key, secret = secret):\n",
    "    #Next page values don't matter here - if they go beyond 4 or 5, they have to do with disconnects which\n",
    "    #are already captured\n",
    "    m_ids = meeting_df.meeting_id.unique().tolist()\n",
    "    meet_data = []\n",
    "    count = 0\n",
    "    client = ZoomClient(key, secret)\n",
    "    #meet_dict = {}\n",
    "    \n",
    "    for m_id in m_ids:\n",
    "        \n",
    "        #insert exception in case of expiration to reset client if necessary\n",
    "        \n",
    "        meet_dict = {'meeting_id':m_id}\n",
    "        try:\n",
    "            p_list = json.loads(client.metric.list_participants(meeting_id = str(m_id), \n",
    "                                                type = 'past').content)['participants']\n",
    "        except KeyError:\n",
    "            time.sleep(0.3)\n",
    "            #Refresh authorization\n",
    "            client = ZoomClient(key, secret)\n",
    "            \n",
    "            try:\n",
    "                p_list = json.loads(client.metric.list_participants(meeting_id = str(m_id), \n",
    "                                            type = 'past').content)['participants']\n",
    "            except KeyError:\n",
    "                meet_data.append(meet_dict)\n",
    "                count += 1\n",
    "                continue\n",
    "        #Define p_list and p_qos once outside per m_id, to reduce server calls\n",
    "\n",
    "        for ind in range(len(p_list)):\n",
    "            #this internal loop will grab all participants in that m_id\n",
    "            #meet_dict[f'participant_{ind + 1}'] = p_list[ind]['user_name']\n",
    "            for key in p_list[ind].keys():\n",
    "                meet_dict[f'{key}_{ind}'] = p_list[ind][key]\n",
    "\n",
    "        #This is done outside of this \"inner\" loop of participants, but would be done for each m_id in all m_ids\n",
    "        meet_data.append(meet_dict)\n",
    "\n",
    "        time.sleep(0.3)\n",
    "    if return_json == True:\n",
    "        ret_dict = {}\n",
    "        for record in range(len(meet_data)):\n",
    "            ret_dict[record] = meet_data[record]\n",
    "        return ret_dict\n",
    "        \n",
    "    participant_df = pd.DataFrame(meet_data)\n",
    "    participant_df.meeting_id = participant_df.meeting_id.apply(lambda x: int(x))\n",
    "    ret_df = meeting_df.merge(participant_df, on = 'meeting_id')\n",
    "    \n",
    "    print(count)\n",
    "    print(count / len(m_ids))\n",
    "    return ret_df\n",
    "\n",
    "def generate_disconnect_cols(df):\n",
    "    leave_cols = [i for i in df.columns if 'leave_reason_' in i]\n",
    "    \n",
    "    #This has to be generalizable as I don't now in advance how many columns will exist\n",
    "    for ind in range(len(leave_cols)):\n",
    "        df[f'connection_failure_{ind}'] = df[leave_cols[ind]].apply(is_disconnected)\n",
    "    \n",
    "    df = df.drop(columns = leave_cols)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def is_disconnected(val):\n",
    "    if pd.isnull(val):\n",
    "        return np.NaN\n",
    "    \n",
    "    if 'disconnected' in val:\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def test_simplifier(df, minim = 3, maxim = 45):\n",
    "    drop_nums = []\n",
    "    for num in range(minim, maxim):\n",
    "        drop_nums.append(f'_{num}')\n",
    "    \n",
    "    \n",
    "    ret_df = df.copy()\n",
    "    \n",
    "    drop_cols = []\n",
    "    for col in ret_df.columns:\n",
    "        for num in drop_nums:\n",
    "            if num in col:\n",
    "                drop_cols.append(col)\n",
    "    \n",
    "    ret_df.drop(columns = drop_cols, inplace = True)\n",
    "    return ret_df\n",
    "\n",
    "def get_qos_vals(m_id, key = key, secret = secret):#, df): \n",
    "    client = ZoomClient(key, secret)\n",
    "    #This will store each list of metrics, to be paired to users, and finally paired to meetings later\n",
    "    all_participants = []\n",
    "    \n",
    "    #This may be a wrapped function - in which case, we can pass q_qos in later from an \"outer\" function\n",
    "    \n",
    "    qos_metrics = json.loads(client.metric.list_participants_qos(\n",
    "            meeting_id = str(m_id), type = 'past').content)#['participants'][0]['user_qos']\n",
    "    \n",
    "    #p_qos = qos_metrics['participants'][0]['user_qos']\n",
    "    \n",
    "    all_participants.append(qos_metrics['participants'][0]['user_qos'])\n",
    "    try:\n",
    "        metrics = [i for i in all_participants[0][0].keys()]# if 'cpu_usage' not in i]\n",
    "        metrics.remove('date_time')\n",
    "    except:\n",
    "        print(f'{m_id} throws an error')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        next_one = json.loads(client.metric.list_participants_qos(meeting_id = str(m_id), \n",
    "                                        type = 'past', next_page_token = qos_metrics['next_page_token']).content)\n",
    "        \n",
    "        all_participants.append(next_one['participants'][0]['user_qos'])\n",
    "        while True:\n",
    "            if 'next_page_token' not in next_one.keys():\n",
    "                break\n",
    "            if next_one['next_page_token'] == '':\n",
    "                break\n",
    "            next_one = json.loads(client.metric.list_participants_qos(meeting_id = str(m_id),\n",
    "                                        type = 'past', next_page_token = next_one['next_page_token']).content)\n",
    "            all_participants.append(next_one['participants'][0]['user_qos'])\n",
    "            \n",
    "        \n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    users = {}\n",
    "    for user in range(len(all_participants)):\n",
    "        users[f'user_{user}'] = all_participants[user]\n",
    "        \n",
    "    \n",
    "    for p_qos in users.keys():\n",
    "        #This will assemble all minutes, then replace the current users data\n",
    "        qos_vals = {}\n",
    "        for ind in range(len(users[p_qos])):\n",
    "            for i in metrics:\n",
    "            #    qos_vals.append(p_qos[0][i].keys())\n",
    "                if ind == 0:\n",
    "                    for q in users[p_qos][ind][i]:\n",
    "\n",
    "                        if users[p_qos][ind][i][q] == '':\n",
    "                            qos_vals[f'{i}_{q}'] = []\n",
    "\n",
    "                        else:\n",
    "                            qos_vals[f'{i}_{q}'] = [users[p_qos][ind][i][q]]\n",
    "                else:\n",
    "                    for q in users[p_qos][ind][i]:\n",
    "\n",
    "                        if users[p_qos][ind][i][q] == '':\n",
    "                            continue\n",
    "                            #qos_vals[f'{i}_{q}'].append(np.NaN)\n",
    "\n",
    "                        else:\n",
    "                            try:\n",
    "                                qos_vals[f'{i}_{q}'].append(users[p_qos][ind][i][q])\n",
    "                            except KeyError:\n",
    "                                #print(f'error in {m_id}')\n",
    "                                continue\n",
    "        users[p_qos] = qos_vals\n",
    "\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23cde94d-22c8-4ef4-a794-05842d9a39a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qos_from_m_id(m_id, durations_dict = None, secret = secret, key = key): \n",
    "    client = ZoomClient(key, secret)\n",
    "    #Make sure to include the dictionary of meeting durations\n",
    "    q_stats = {'meeting_id':m_id}\n",
    "    if durations_dict != None:\n",
    "        q_stats['duration'] = durations_dict[m_id]\n",
    "    #This is now a dictionary of users, each pairing to a dictionary of metrics, each paired to a list of metrics\n",
    "    users = get_qos_vals(m_id)\n",
    "#     print(qos_vals.keys())\n",
    "    pass_cols = ['cpu_usage_zoom_min_cpu_usage', 'cpu_usage_zoom_avg_cpu_usage', \n",
    "             'cpu_usage_zoom_max_cpu_usage', 'cpu_usage_system_max_cpu_usage']\n",
    "\n",
    "    #This needs to now generate {x} in addition, for numbers of users 0 - x.\n",
    "    for qos_vals in users.keys():\n",
    "        num = qos_vals.split('_')[1]\n",
    "        for key in users[qos_vals].keys():\n",
    "            count = 0\n",
    "            if key in pass_cols:\n",
    "                 continue\n",
    "\n",
    "            if users[qos_vals][key] == []:\n",
    "                if 'resolution' in key:\n",
    "                    q_stats[f'{key}_{num}'] = np.NaN\n",
    "                else:\n",
    "                    q_stats[f'{key}_bad_mins_{num}'] = np.NaN\n",
    "                    q_stats[f'{key}_bad_mins_{num}'] = np.NaN\n",
    "                    q_stats[f'{key}_bad_mins_{num}'] = np.NaN  \n",
    "\n",
    "                continue\n",
    "\n",
    "            if 'resolution' in key:\n",
    "                q_stats[f'{key}_{num}'] = users[qos_vals][key][0]\n",
    "                continue\n",
    "\n",
    "            if '%' in users[qos_vals][key][0]:\n",
    "                #create a separate for comp and avg/max losses\n",
    "                #loss should be <= 2%, so unnaceptable may be over 4%\n",
    "                v_list = [float(q[:-1]) for q in users[qos_vals][key]]\n",
    "                tag = '%'\n",
    "\n",
    "                if '_loss' in key:\n",
    "                    for val in v_list:\n",
    "                        if val > 4.0:\n",
    "                            count += 1\n",
    "                    q_stats[f'{key}_min_{num}'] = f'{np.min(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_avg_performance_{num}'] = f'{np.round(np.mean(v_list), 2)}{tag}'\n",
    "                    q_stats[f'{key}_max_{num}'] = f'{np.max(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_bad_mins_{num}'] = int(count)\n",
    "                    q_stats[f'{key}_bad_ratio_{num}'] = np.round((count / len(v_list)), 2)\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] > 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 1\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] <= 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 0\n",
    "\n",
    "                if 'cpu' in key and 'max' in key:\n",
    "                    if val > 70:\n",
    "                        count +=1\n",
    "                    q_stats[f'{key}_min_{num}'] = f'{np.min(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_avg_performance_{num}'] = f'{np.round(np.mean(v_list), 2)}{tag}'\n",
    "                    q_stats[f'{key}_max_{num}'] = f'{np.max(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_bad_mins_{num}'] = int(count)\n",
    "                    q_stats[f'{key}_bad_ratio_{num}'] = np.round((count / len(v_list)), 2)\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] > 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 1\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] <= 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 0\n",
    "\n",
    "                if 'cpu' in key and 'max' not in key:\n",
    "                    for val in v_list:\n",
    "                        if val > 25:\n",
    "                            count +=1\n",
    "                    q_stats[f'{key}_min_{num}'] = f'{np.min(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_avg_performance_{num}'] = f'{np.round(np.mean(v_list), 2)}{tag}'\n",
    "                    q_stats[f'{key}_max_{num}'] = f'{np.max(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_bad_mins_{num}'] = int(count)\n",
    "                    q_stats[f'{key}_bad_ratio_{num}'] = np.round((count / len(v_list)), 2)\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] > 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 1\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] <= 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 0\n",
    "\n",
    "                continue\n",
    "\n",
    "\n",
    "            else:\n",
    "                v_list = [int(q.split()[0]) for q in users[qos_vals][key]]\n",
    "                tag = users[qos_vals][key][0].split()[1]\n",
    "\n",
    "                if 'audio' in key and 'bitrate' in key:\n",
    "                    #60-100 kbps is optimal, so under 40 could be \"unacceptable\"\n",
    "                    for val in v_list:\n",
    "                        if val < 40:\n",
    "                            count += 1\n",
    "                    q_stats[f'{key}_min_{num}'] = f'{np.min(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_avg_performance_{num}'] = f'{np.round(np.mean(v_list), 2)}{tag}'\n",
    "                    q_stats[f'{key}_max_{num}'] = f'{np.max(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_bad_mins_{num}'] = int(count)\n",
    "                    q_stats[f'{key}_bad_ratio_{num}'] = np.round((count / len(v_list)), 2)\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] > 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 1\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] <= 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 0                \n",
    "\n",
    "\n",
    "                if 'video' in key and 'bitrate' in key:\n",
    "                    #600 is recommended, so under 400 is unacceptable\n",
    "                    for val in v_list:\n",
    "                        if val < 400:\n",
    "                            count += 1\n",
    "                    q_stats[f'{key}_min_{num}'] = f'{np.min(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_avg_performance_{num}'] = f'{np.round(np.mean(v_list), 2)}{tag}'\n",
    "                    q_stats[f'{key}_max_{num}'] = f'{np.max(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_bad_mins_{num}'] = int(count)\n",
    "                    q_stats[f'{key}_bad_ratio_{num}'] = np.round((count / len(v_list)), 2)\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] > 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 1\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] <= 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 0                \n",
    "\n",
    "                if 'latency' in key:\n",
    "                    #latency should be under 150 ms for both audio and video\n",
    "                    for val in v_list:\n",
    "                        if val > 100:\n",
    "                            count += 1\n",
    "                    q_stats[f'{key}_min_{num}'] = f'{np.min(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_avg_performance_{num}'] = f'{np.round(np.mean(v_list), 2)}{tag}'\n",
    "                    q_stats[f'{key}_max_{num}'] = f'{np.max(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_bad_mins_{num}'] = int(count)\n",
    "                    q_stats[f'{key}_bad_ratio_{num}'] = np.round((count / len(v_list)), 2)\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] > 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 1\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] <= 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 0                \n",
    "\n",
    "                if 'jitter' in key:\n",
    "                    #jitter should be under 40 ms for both audio and video\n",
    "                    for val in v_list:\n",
    "                        if val > 60:\n",
    "                            count += 1\n",
    "                    q_stats[f'{key}_min_{num}'] = f'{np.min(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_avg_performance_{num}'] = f'{np.round(np.mean(v_list), 2)}{tag}'\n",
    "                    q_stats[f'{key}_max_{num}'] = f'{np.max(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_bad_mins_{num}'] = int(count)\n",
    "                    q_stats[f'{key}_bad_ratio_{num}'] = np.round((count / len(v_list)), 2)\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] >= 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 1\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] < 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 0                \n",
    "\n",
    "                if 'framerate' in key:\n",
    "                    #30 is max, less than 15 is not acceptable\n",
    "                    for val in v_list:\n",
    "                        if val < 18:\n",
    "                            count += 1\n",
    "                    q_stats[f'{key}_min_{num}'] = f'{np.min(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_avg_performance_{num}'] = f'{np.round(np.mean(v_list), 2)}{tag}'\n",
    "                    q_stats[f'{key}_max_{num}'] = f'{np.max(v_list)}{tag}'\n",
    "                    q_stats[f'{key}_bad_mins_{num}'] = int(count)\n",
    "                    q_stats[f'{key}_bad_ratio_{num}'] = np.round((count / len(v_list)), 2)\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] > 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 1\n",
    "\n",
    "                    if q_stats[f'{key}_bad_ratio_{num}'] <= 0.4:\n",
    "                        q_stats[f'{key}_poor_meeting_{num}'] = 0                \n",
    "                \n",
    "\n",
    "    return q_stats\n",
    "\n",
    "def qos_df(meeting_df, secret = secret, key = key):\n",
    "    m_ids = meeting_df.meeting_id.unique().tolist()\n",
    "    m_ids = [str(i) for i in m_ids]\n",
    "    \n",
    "    ret_vals = []\n",
    "\n",
    "    for meeting in m_ids:\n",
    "        #qos_vals = get_qos_vals(meeting)\n",
    "        try:\n",
    "            q_stats = generate_qos_from_m_id(meeting)\n",
    "            ret_vals.append(q_stats)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    m_df = pd.DataFrame(ret_vals)\n",
    "    m_df.meeting_id = m_df.meeting_id.apply(lambda x: int(x))\n",
    "    \n",
    "    ret_df = meeting_df.merge(m_df, how = 'left', on = 'meeting_id')\n",
    "    \n",
    "    return pd.DataFrame(ret_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
